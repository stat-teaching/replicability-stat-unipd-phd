{
  "hash": "efc1249414e5f63065639becdff451fe",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Multiverse\nsubtitle: Replicability Crisis in Science?\ncode-fold: true\n---\n\n\n\n\n\n# Multiverse analysis {.section}\n\n## Multiverse analysis @Steegen2016-lz\n\n- Even a simple data analysis is characterized by several (often arbitrary) choices\n- The impact of these choices is not always clear, known or easy to predict\n- Researchers (with or without awareness) usually report a single set of choices \n\n## Some examples\n\n- using a predictor as continous or choosing some thresholds and transforming to categorical\n- including or excluding an observation (e.g., outlier)\n- including or excluding a covariate (e.g., controlling for age or not)\n- using a linear model or an ordinal regression for discrete ordered data\n- ...\n\n## The garden of forking paths\n\nA tree of possibilities...\n\n![](img/forking-paths.svg)\n\n## The garden of forking paths\n\n... Where only some of them produce a certain result.\n\n![](img/forking-paths-color.svg)\n\n\n## Only plausible vs all scenarios\n\nNot all scenarios are equally plausible or reasonable. Thus the multiverse is not the entire set but a non-random sample of plausibile choices.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx <- seq(0, 1, 0.0001)\ny <- dexp(x, 2)\ny <- (y-min(y))/(max(y)-min(y))\n\nplot(x*100, y, type = \"l\",\n     xlab = \"All possible scenarios\",\n     ylab = \"Plausibility\",\n     lwd = 2)\n```\n\n::: {.cell-output-display}\n![](04-multiverse-meta-analysis_files/figure-revealjs/unnamed-chunk-2-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n\n# Multiverse meta-analysis {.section}\n\n## Meta-analysis many choices\n\nDespite useful and very powerful, meta-analysis is characterized by several (arbitrary) choices. For example:\n\n- Should the study $x$ be excluded for theoretical or statistical (e.g., outliers) reasons?\n- Should we use an equal or random-effects model?\n- Which value should take the pre-post missing correlation?\n- ...\n\n## An example: Pre-post designs\n\nLet's imagine that we have $k$ studies about the efficacy of a certain treatment. They collected a sample of participants measuring a certain variable $y$ before and after the treatment.\n\nWith this design we can summarise the effect computing the difference between the average of the two time points.\n\nAn effect size (e.g., Cohen's $d$) can be calculated as:\n\n$$\nd = \\frac{\\overline y_{post} - \\overline y_{pre}}{\\sigma_p}\n$$\n\nAnd $\\sigma_p$ is the pooled pre-post standard deviation.\n\n## An example: Pre-post Cohen's $d$\n\nWith a pre-post Cohen's $d$ we need the pre-post correlation $\\rho$ to calculate the sampling variance:\n\n$$\n\\sigma^2_{\\epsilon_{pp}} = \\frac{2(1 - \\rho)}{n} + \\frac{d^2}{2n}\n$$\n\n$\\rho$ is usually non reported and need to be chosen from previous literature or a plausible guess.\n\n## Pre-post Cohen's $d$\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nv_dm <- function(r, d, n){\n    2*(1-r)/n + d^2/(2*n)\n}\n\nvdd <- data.frame(x = seq(-1, 1, 0.001))\nvdd$y <- v_dm(vdd$x, 0, 40)\n\nggplot(vdd, aes(x = x, y = y)) +\n    geom_line() +\n    xlab(expression(rho)) +\n    ylab(expression(sigma^2)) +\n    theme_minimal(25)\n```\n\n::: {.cell-output-display}\n![](04-multiverse-meta-analysis_files/figure-revealjs/unnamed-chunk-3-1.svg){fig-align='center' width=100%}\n:::\n:::\n\n\n\n## A simulated example\n\n\n\n\n\n\n\nThe data structure: multiple measures of the same outcome within each paper\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-condensed\" style=\"font-size: 25px; width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> study </th>\n   <th style=\"text-align:left;\"> outcome </th>\n   <th style=\"text-align:left;\"> ni </th>\n   <th style=\"text-align:left;\"> yi </th>\n   <th style=\"text-align:left;\"> vi </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:left;\"> 25 </td>\n   <td style=\"text-align:left;\"> 0.65 </td>\n   <td style=\"text-align:left;\"> 0.09 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:left;\"> 2 </td>\n   <td style=\"text-align:left;\"> 25 </td>\n   <td style=\"text-align:left;\"> 0.42 </td>\n   <td style=\"text-align:left;\"> 0.08 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:left;\"> 3 </td>\n   <td style=\"text-align:left;\"> 25 </td>\n   <td style=\"text-align:left;\"> -0.71 </td>\n   <td style=\"text-align:left;\"> 0.09 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:left;\"> 88 </td>\n   <td style=\"text-align:left;\"> -0.07 </td>\n   <td style=\"text-align:left;\"> 0.02 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2 </td>\n   <td style=\"text-align:left;\"> 2 </td>\n   <td style=\"text-align:left;\"> 88 </td>\n   <td style=\"text-align:left;\"> 0.15 </td>\n   <td style=\"text-align:left;\"> 0.02 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ... </td>\n   <td style=\"text-align:left;\"> ... </td>\n   <td style=\"text-align:left;\"> ... </td>\n   <td style=\"text-align:left;\"> ... </td>\n   <td style=\"text-align:left;\"> ... </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 9 </td>\n   <td style=\"text-align:left;\"> 3 </td>\n   <td style=\"text-align:left;\"> 72 </td>\n   <td style=\"text-align:left;\"> -0.03 </td>\n   <td style=\"text-align:left;\"> 0.03 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 9 </td>\n   <td style=\"text-align:left;\"> 4 </td>\n   <td style=\"text-align:left;\"> 72 </td>\n   <td style=\"text-align:left;\"> -0.82 </td>\n   <td style=\"text-align:left;\"> 0.03 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 9 </td>\n   <td style=\"text-align:left;\"> 5 </td>\n   <td style=\"text-align:left;\"> 72 </td>\n   <td style=\"text-align:left;\"> 0.13 </td>\n   <td style=\"text-align:left;\"> 0.03 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 10 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:left;\"> 164 </td>\n   <td style=\"text-align:left;\"> 0.24 </td>\n   <td style=\"text-align:left;\"> 0.01 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 10 </td>\n   <td style=\"text-align:left;\"> 2 </td>\n   <td style=\"text-align:left;\"> 164 </td>\n   <td style=\"text-align:left;\"> 0.58 </td>\n   <td style=\"text-align:left;\"> 0.01 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n## Simulation approach\n\nLet's make an example for a paper with $j = 3$ measures of the outcome:\n\n$$\n\\begin{bmatrix}\n        y_{11} \\\\\n        y_{12} \\\\\n        y_{13}\n    \\end{bmatrix}\n    =\n    \\begin{bmatrix}\n        \\mu_{\\theta_1} \\\\\n        \\mu_{\\theta_2} \\\\\n        \\mu_{\\theta_3}\n    \\end{bmatrix}\n    +\n    \\begin{bmatrix}\n        \\delta_{\\theta_1} \\\\\n        \\delta_{\\theta_2} \\\\\n        \\delta_{\\theta_3}\n    \\end{bmatrix}\n    +\n    \\begin{bmatrix}\n        \\epsilon_{\\theta_{11}} \\\\\n        \\epsilon_{\\theta_{12}} \\\\\n        \\epsilon_{\\theta_{13}}\n\\end{bmatrix}\n$$\n\n$$\n\\boldsymbol{\\delta} \\sim \\text{MVN}\\left(\n    \\begin{matrix}\n    0 \\\\\n    0 \\\\\n    0\n    \\end{matrix}\n    \\\n    \\begin{matrix}\n        \\tau^2_1 &        & \\\\\n        \\rho_{21}\\tau_2\\tau_1        & \\tau^2_1 & \\\\\n         \\rho_{31}\\tau_2\\tau_1        &  \\rho_{32}\\tau_2\\tau_1        & \\tau^2_1 \\\\\n    \\end{matrix}\n    \\right)\n$$\n\n$$\n\\boldsymbol{\\epsilon} \\sim \\text{MVN}\\left(\n    \\begin{matrix}\n    0 \\\\\n    0 \\\\\n    0\n    \\end{matrix}\n    \\\n    \\begin{matrix}\n        \\sigma^2_{\\epsilon_1} &        & \\\\\n        \\rho_{21}\\sigma^2_{\\epsilon_2}\\sigma^2_{\\epsilon_1}        & \\sigma^2_{\\epsilon_2} & \\\\\n        \\rho_{31}\\sigma^2_{\\epsilon_3}\\sigma^2_{\\epsilon_1}         &  \\rho_{32}\\sigma^2_{\\epsilon_3}\\sigma^2_{\\epsilon_2}        & \\sigma^2_{\\epsilon_3} \\\\\n    \\end{matrix}\n    \\right)\n$$\n\n## Simulation approach\n\nWe simulated individual participant data, thus:\n\n1. Sampling the true values $\\theta_{ij}$ for each study $i$ and outcome $j$ from the multivariate distribution\n2. Generating $n_i$ pre and post data with correlation $\\rho$\n3. Calculating the effect size (imputing the pre-post correlation)\n5. Aggregating multiple outcomes within the same paper (imputing the correlation)\n4. Fitting the meta-analyis model\n5. Calculating the scores\n7. Repeating 3-4 for each scenario\n6. Using PIMA\n\n## Simulation approach\n\nWe simulated a relatively simple but plausible multiverse with:\n\n- 4 pre-post correlations\n- 4 correlations between multiple measures of the same outcome\n- 2 meta-analysis models (fixed and random-effects)\n\nFor a total of 32 multiverse scenarios.\n\n## Results\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np_beta <- ggplot(multi, aes(y = b)) +\n    xlim(c(-0.5,0.5)) +\n    geom_boxplot(width = 0.5,\n                 fill = \"dodgerblue\",\n                 alpha = 0.6) + \n    ylab(latex2exp::TeX(\"$\\\\mu_{\\\\,\\\\, \\\\theta}$\")) +\n    theme_minimal(30) +\n    theme(axis.text.x = element_blank())\n\np_pval <- ggplot(multi, aes(y = -log10(p.value))) +\n    xlim(c(-0.5,0.5)) +\n    geom_hline(yintercept = -log10(0.05)) +\n    geom_boxplot(width = 0.5,\n                 fill = \"dodgerblue\",\n                 alpha = 0.6) + \n    ylab(latex2exp::TeX(\"Raw $-log_{10}(p)$\")) +\n    theme_minimal(30) +\n    theme(axis.text.x = element_blank())\n\nrdata <- cor(zi)\nrdata <- data.frame(r = rdata[upper.tri(rdata, diag = FALSE)])\n\np_cor <- ggplot(rdata, aes(y = r)) +\n    xlim(c(-0.5,0.5)) +\n    geom_boxplot(width = 0.5,\n                 fill = \"dodgerblue\",\n                 alpha = 0.6) + \n    ylab(latex2exp::TeX(\"$\\\\rho$\")) +\n    theme_minimal(30) +\n    theme(axis.text.x = element_blank()) +\n    ylim(c(-1,1))\n\ncowplot::plot_grid(p_beta, p_cor, p_pval, nrow = 1)\n```\n\n::: {.cell-output-display}\n![](04-multiverse-meta-analysis_files/figure-revealjs/unnamed-chunk-6-1.svg){fig-align='center' width=80%}\n:::\n:::\n\n\n\n## An example from @Plessen2023-ex\n\n![](img/plessen2023.png)\n\n## An example from @Plessen2023-ex\n\n- Over the last four decades, more than 80 meta-analyses have examined the efficacy of psychotherapies for depression\n- More than 700 randomised controlled trials (RCTs)\n- Not all these studies goes in the same direction\n\n## An example from @Plessen2023-ex\n\nDiscrepancies in results could be due to:\n\n### Which factors (which data to meta-analyze)\n\n- inclusion/esclusion of a subset of studies (e.g., low quality studies)\n- type of control group or control therapy\n- ...\n\n### How factors (how to meta-analyze)\n\n- type of model (e.g., equal vs random)\n- model complexity (two-level, three level, robust, etc.)\n- correcting for publication bias\n\n# Descriptive tools {.section}\n\n## Describing the multiverse\n\n@Hall2022-mp and @Liu2021-xv proposed several tools to describe the results of a multiverse analysis.\n\nThe increase in complexity NEED to be managed using appropriate tools to summarise and visualize the results.\n\n## Estimated effect of interest\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nspecif_res |> \n  ggplot(aes(x = b)) +\n  geom_histogram(bins = 50,\n                 fill = \"dodgerblue\",\n                 col = \"black\") +\n  ylab(\"Frequency\") +\n  xlab(\"Estimated Effect\") +\n  geom_vline(xintercept = 0, col = \"red\") +\n  geom_vline(xintercept = 0.25, col = \"green\")\n```\n\n::: {.cell-output-display}\n![](04-multiverse-meta-analysis_files/figure-revealjs/unnamed-chunk-7-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n\n## Estimated effect as a function of scenarios^[The red line is the 0 effect and the green line is a minimum effect of interest in the research field]\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nabove <- specif_res |> \n  arrange(b) |> \n  mutate(id = 1:n()) |> \n  ggplot(aes(x = id, y = b)) +\n  geom_segment(aes(xend = id, y = ci.lb, yend = ci.ub)) +\n  geom_hline(yintercept = 0, col = \"red\") +\n  geom_hline(yintercept = 0.25, col = \"green\") +\n  theme(axis.title.y = element_blank(),\n        axis.text.x = element_blank(),\n        axis.title.x = element_blank())\n  \nbelow <- specif_res |> \n  arrange(b) |> \n  mutate(id = 1:n()) |> \n  pivot_longer(c(\n    target_group,\n    format,\n    diagnosis,\n    risk_of_bias,\n    type,\n    method\n  )) |> \n  ggplot(aes(x = id, y = value)) +\n  geom_tile() +\n  theme(axis.title.y = element_blank(),\n        axis.text.x = element_blank()) +\n  xlab(\"Specification\")\n\nplot_grid(above, below, nrow = 2, align = \"hv\")\n```\n\n::: {.cell-output-display}\n![](04-multiverse-meta-analysis_files/figure-revealjs/unnamed-chunk-8-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n\n## Fixing a specific parameter\n\nWe can the effect of a set of scenarios having a certain parameter:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nspecif_res |> \n  arrange(b) |> \n  mutate(id = 1:n()) |> \n  ggplot(aes(x = b, fill = diagnosis)) +\n  geom_density(alpha = 0.5)\n```\n\n::: {.cell-output-display}\n![](04-multiverse-meta-analysis_files/figure-revealjs/unnamed-chunk-9-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n\n# Inferential tools {.section}\n\n## Specification Curve @Simonsohn2020-sr\n\nThe idea of the specification curve is both descriptive (see previous plots) and inferential.\n\nInferentially, the approach requires to generate a new dataset under the null hypothesis and compare with the observed value.\n\n## Specification Curve in meta-analysis @Plessen2023-ex\n\n@Plessen2023-ex describe how to implement the method for meta-analysis.\n\n1. For each dataset/model generate $k_s$ data (where $k$ is the number of effect in the specification $s$) sampling from $\\mathcal{N}(0,\\sigma^2_{\\epsilon_i} + \\tau^2)$.\n2. Fit the model (FE or RE)\n3. Get the specification curve\n4. Repeat 1-3 for a large number of times (e.g., 1000)\n5. Compute the 2.5% and 95.75% quantiles\n6. Check if the observed specification is outside the 95% CI\n\n## Specification Curve in meta-analysis @Plessen2023-ex\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nspecif$SD |> \n  filter(spec %in% sample(1:1000, 1)) |> \n  ggplot(aes(x = id, y = b)) +\n  geom_line(aes(group = spec))\n```\n\n::: {.cell-output-display}\n![](04-multiverse-meta-analysis_files/figure-revealjs/unnamed-chunk-10-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n\n## Specification Curve in meta-analysis @Plessen2023-ex\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nspecif$SD |> \n  filter(spec %in% sample(1:1000, 1)) |> \n  ggplot(aes(x = id, y = b)) +\n  geom_line(aes(group = spec))\n```\n\n::: {.cell-output-display}\n![](04-multiverse-meta-analysis_files/figure-revealjs/unnamed-chunk-11-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n\n## Specification Curve in meta-analysis @Plessen2023-ex\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nspecif$SD |> \n  filter(spec %in% sample(1:1000, 1)) |> \n  ggplot(aes(x = id, y = b)) +\n  geom_line(aes(group = spec))\n```\n\n::: {.cell-output-display}\n![](04-multiverse-meta-analysis_files/figure-revealjs/unnamed-chunk-12-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n\n## Specification Curve in meta-analysis @Plessen2023-ex\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nspecif_res <- specif_res |> \n  arrange(b) |> \n  mutate(id = 1:n())\n\nggplot(data = specif$SD,\n       aes(x = id, y = b)) +\n  geom_line(aes(group = spec)) +\n  geom_line(data = specif_res,\n            aes(x = id, y = b),\n            col = \"firebrick\",\n            lwd = 2)\n```\n\n::: {.cell-output-display}\n![](04-multiverse-meta-analysis_files/figure-revealjs/unnamed-chunk-13-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n\n## PIMA\n\n**P**-selection **I**nference in **M**ultiverse **M**eta-analysis (PIMA) is an inferential approach to multiverse analysis is an inferential framework for:\n\n- obtaining an overall p-value across the multiverse\n- obtaining corrected p-values based on resampling methods\n\n## PIMA [@Girardi2024-ip]\n\n![](img/girardi2024.pdf){width=80% fig-align=\"center\"}\n\n## PIMA on meta-analysis\n\nWe implemented PIMA also on meta-analysis but (for the moment) limited to two-level models without moderators.\n\n![](img/wip.jpg)\n\n## PIMA Results\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmulti_flip_overall <- flip::npc(multi_flip, comb.funct = \"maxT\")\nmulti_p <- multi_flip_overall@res$`p-value`\nfp <- function(p){\n    ifelse(p <= 0.001, \"p < 0.001\", as.character(round(p, 3)))\n}\n```\n:::\n\n\n\nThe multiverse is associated with an overall p value of 0.016 ^[combined using the maxT method by @Westfall1993-ek]. Then we can describe the overall results:\n\n\n\n::: {.cell layout-align=\"center\" fig-out='80%'}\n\n```{.r .cell-code}\np_beta <- ggplot(multi, aes(y = b)) +\n    xlim(c(-0.5,0.5)) +\n    geom_boxplot(width = 0.5,\n                 fill = \"dodgerblue\",\n                 alpha = 0.6) + \n    ylab(latex2exp::TeX(\"$\\\\mu_{\\\\,\\\\, \\\\theta}$\")) +\n    theme_minimal(30) +\n    theme(axis.text.x = element_blank())\n\np_pval <- ggplot(multi, aes(y = -log10(p.value))) +\n    xlim(c(-0.5,0.5)) +\n    geom_hline(yintercept = -log10(0.05)) +\n    geom_boxplot(width = 0.5,\n                 fill = \"dodgerblue\",\n                 alpha = 0.6) + \n    ylab(latex2exp::TeX(\"Raw $-log_{10}(p)$\")) +\n    theme_minimal(30) +\n    theme(axis.text.x = element_blank())\n\nrdata <- cor(zi)\nrdata <- data.frame(r = rdata[upper.tri(rdata, diag = FALSE)])\n\np_cor <- ggplot(rdata, aes(y = r)) +\n    xlim(c(-0.5,0.5)) +\n    geom_boxplot(width = 0.5,\n                 fill = \"dodgerblue\",\n                 alpha = 0.6) + \n    ylab(latex2exp::TeX(\"$\\\\rho$\")) +\n    theme_minimal(30) +\n    theme(axis.text.x = element_blank()) +\n    ylim(c(-1,1))\n\ncowplot::plot_grid(p_beta, p_cor, p_pval, nrow = 1)\n```\n\n::: {.cell-output-display}\n![](04-multiverse-meta-analysis_files/figure-revealjs/unnamed-chunk-15-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n\n## Impact of multiplicity correction\n\n\n\n::: {.cell layout-align=\"center\" fig-out='100%'}\n\n```{.r .cell-code}\ntp <- function(p){\n    -log10(p)\n}\n\nlbl <- c(\"Never $p \\\\leq 0.05$\", \n         \"Before correction $p \\\\leq 0.05$\", \n         \"After correction $p \\\\leq 0.05$\")\n\n\nmulti$sign <- factor(multi$sign, \n                     labels = latex2exp::TeX(lbl))\n\nggplot(multi, aes(x = tp(p.value), tp(adjust.maxt), color = sign)) +\n    geom_hline(yintercept = tp(0.05), alpha = 0.4) +\n    geom_vline(xintercept = tp(0.05), alpha = 0.4) +\n    geom_abline(linetype = \"dashed\", lwd = 0.5) +\n    geom_point(size = 5,\n               position = position_jitter(width = 0.1),\n               alpha = 0.5) +\n    xlim(c(0, 3)) +\n    ylim(c(0, 3)) +\n    xlab(TeX(\"Raw p value ($-log_{10}$)\")) +\n    ylab(TeX(\"maxT p value ($-log_{10}$)\")) +\n    theme_minimal(base_size = 20) +\n    theme(legend.title = element_blank(),\n          legend.position = \"bottom\") +\n    scale_color_manual(labels = scales::parse_format(), values = c(\"#F8766D\", \"#7CAE00\", \"#00BFC4\"))\n```\n\n::: {.cell-output-display}\n![](04-multiverse-meta-analysis_files/figure-revealjs/unnamed-chunk-16-1.svg){fig-align='center' width=768}\n:::\n:::\n\n\n\n# Important aspects of multiverse analysis {.section}\n\n## Important aspects of multiverse analysis\n\n- Include only plausible scenarios. Regardless the aim (description or inference) of the multiverse, the results are meaningful if and only if scenarios are plausible.\n- Scenarios are assumed to be equally plausible but we could imagine a plausibility weight (future direction)\n- Multiverse analysis is also useful to estimate the degree of variability according to plausible choices\n\n# Some other multiverse examples and resources {.section}\n\n## R Packages\n\n- https://mucollective.github.io/multiverse/\n- https://mverseanalysis.github.io/mverse/\n- https://github.com/uwdata/boba\n\n## Multiverse projects\n\n- @Dafflon2022-zl implemented a multiverse analysis for neuroimaging data\n- @Hoogeveen2023-dw implemented a Bayesian multiverse analysis within the Many Labs 4 project (a large scale replication project in Psychology)\n- @Olsson-Collentine2023-sj re-analyzed some replication projects using a multiverse approach\n\n## Multiverse is catchy!\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmulti_cit <- data.frame(\n        year = c(2024L,2023L,2022L,2021L,2020L,2019L,\n                 2018L,2017L,2016L,2015L,2014L,2013L),\n      papers = c(30L, 46L, 33L, 19L, 10L, 11L, 4L, 2L, 3L, 0L, 1L, 1L),\n       total = c(652674L,1295092L,1317981L,1299609L,\n                 1161910L,1044346L,955091L,907118L,874112L,840256L,804004L,\n                 777242L)\n)\n\nmulti_cit |> \n    mutate(year = as.integer(year)) |> \n    ggplot(aes(x = year, y = papers/total)) +\n    geom_line() +\n    geom_label(aes(label = papers)) +\n    scale_x_continuous(breaks = seq(2012, 2024, 1)) +\n    theme(axis.title.x = element_blank(),\n          axis.text.y = element_blank(),\n          axis.ticks.y = element_blank()) +\n    ylab(\"# papers on Multiverse\")\n```\n\n::: {.cell-output-display}\n![](04-multiverse-meta-analysis_files/figure-revealjs/unnamed-chunk-17-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n\n## References\n\n::: {#refs}\n:::\n\n# Extra - PIMA implementation for meta-analysis {.section}\n\n## General Workflow\n \n![](img/workflow.png){fig-align=\"center\"}\n\n## Meta-analysis with permutations [@Follmann1999-ha]\n\nWith $k$ observed studies where $y_i$ and $\\sigma^2_{\\epsilon_i}$ being the observed effect sizes and sampling variances:\n\n1. Generate a random vector $\\mathbf{s}$ of $\\pm 1$ of length $k$\n2. Multiply the $\\mathbf{y}$ vector with the $s$ vector\n3. Fit the meta-analysis model and calculate $z^{*}_j$ ($j$ for permuted)\n4. Repeat 1-3 for a large number of times $B$. With small $k$ we can do all the permutations $B = 2^k \\times k$\n\nThe first permutation ($j = 1$) is the observed data. The p value can be computed as:\n\n$$\np = \\frac{\\text{\\#}(|z^{*}_j| > |z^{*}_1|)}{B}\n$$\n\n## Fast meta-analysis using permutations\n\n- Meta-analysis using permutations requires recomputing $\\tau^2$ and $\\mu_\\theta$ after each permutation.\n\n- We proposed to estimate $\\tau^2$ under $H_0$ and use the value for the permutations (without re-estimating it)\n\n- This is extremely fast especially for large datasets and several multiverse scenarios\n\n## Estimating $\\tau^2$ under $H_0$\n\nThe crucial step is the point (1). This requires maximizing the log-likelihood fixing $\\mu_\\theta = 0$:\n\n$$\nL(\\mu_{\\theta}, \\tau^2|\\mathbf{y}) = -\\frac{1}{2}\\sum_{i = 1}^k \\ln(\\tau^2 + \\sigma_{\\epsilon_i}^2) - \\frac{1}{2} \\sum_{i = 1}^k \\frac{(y_i - \\mu_{\\theta})^2}{\\tau^2 +  \\sigma_{\\epsilon_i}^2}\n$$\n\nThis can be done in R using some optimizer function (e.g., `optim`) or using directly the `metafor` package that allows fixing some parameters that are usually estimated.\n",
    "supporting": [
      "04-multiverse-meta-analysis_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}