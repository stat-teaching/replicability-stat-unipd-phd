---
title: "Multiverse Meta-Analysis Exploring the Efficacy of Psychological Interventions for Depression"
subtitle: "4. Inferential specification curve"
author: "Constantin Yves Plessen"
date: "`r format(Sys.time(), '%d %B, %Y')`"
 
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(metafor)
library(plyr)
library(ggpubr)
library(grid)
library(gridExtra)
library(puniform)
library(svMisc)
library(todor)

library(doParallel) #parallel computations
library(foreach) #parallel computations
library(tidyverse) #data management
library(cowplot) #Arrange Plots
library(doRNG) #parallel computations
library(parallel) #mclapply

options(todor_rmd = T)
set.seed(1234)
options(scipen = 999)

PET.PEESE <- function(data) {
  mod <- list()
  fit_PET <- lm(yi ~ sqrt(vi), 
                weights = 1/vi, 
                data = data)
  
  pet_p <- coef(summary(fit_PET))["(Intercept)", "Pr(>|t|)"] # pet p-value < .10 -> peese
  
  if(pet_p >= .1) {
    mod$b <- coef(summary(fit_PET))["(Intercept)", "Estimate"] # pet estimate
    mod$ci.lb <- confint(fit_PET)["(Intercept)", "2.5 %"] 
    mod$ci.ub<- confint(fit_PET)["(Intercept)", "97.5 %"] 
    mod$pval <- pet_p
    mod$type <- "PET"
    
  }else{
    
    fit_PEESE <- lm(yi ~ vi, 
                    weights = 1/vi, 
                    data = data)
    
    mod$pval <- coef(summary(fit_PEESE))["(Intercept)", "Pr(>|t|)"] # pet p-value < .10 -> peese
    mod$b  <- coef(summary(fit_PEESE))["(Intercept)", "Estimate"] # peese estimate
    mod$ci.lb <- confint(fit_PEESE)["(Intercept)", "2.5 %"] 
    mod$ci.ub <- confint(fit_PEESE)["(Intercept)", "97.5 %"] 
    mod$type <- "PEESE"

  }
  return(mod)
}
```

# Load data

```{r}
dat_boot <- read_csv("data/tidy/data_cleaned.csv")
dat_boot
```

<br>

### Load data for specification curve analysis
```{r load-data-for-bootstrapping}
specifications_inferential_spec_curve <- read.csv2(file = "data/tidy/specifications_cleaned.csv") %>% 
  filter(dependency == "aggregate" & (ma_method == "fe"  | ma_method == "reml" | ma_method == "pet-peese")) 
```

# Inferental Test

<br>

### Load unique specification study subsets found via the "Which" factors 
```{r load-unique-which-factor-combinations-bootstrapping}
sets <- as.vector(unique(specifications_inferential_spec_curve$set))
sets <- lapply(strsplit(sets, ","), as.numeric)
```

<br>

### Number of specifications (number of unique study subsets times number of How Factor Combinations)
```{r number-of-specifications-for-bootstrapping}
no_spec <- length(sets) * 3
```
<br>

### Number of iterations
```{r}
iter <- 1000 # 1000
```

<br>

### Matrix to save bootstrapped specification curves
```{r}
res <- lapply(1:3, function(x) list())
```


```{r}
# Function that takes the ids of studies for each unique 
# specification regarding the included studies (Which factors), 
# and computes the resulting summary effect for each of the 
# "How factors".
spec_list  <- function(ids, data) {
  
  temp1 <- data[ids, ]
  
  # averaging studies due to effect size dependency
  temp2 <- temp1%>% 
    escalc(yi=yi, vi=vi, data=.)
  
  temp <- as.data.frame(
    aggregate(
      temp2, 
      cluster = study,
      struct="CS" , #compound symmetric structure as nested are not indpendent
      rho = 0.5)
  )
  
  spec <- 
    c(rma(yi = yi,  # FE
          vi = vi, 
          method = "FE", 
          data = temp)$b[[1]],
     rma(yi = yi, # REML
        vi = vi, 
        method = "REML", 
        control = list(stepadj = 0.5, maxiter = 2000), 
        data = temp)$b[[1]],
     PET.PEESE(temp)$b[[1]]
      )
  spec
}
```


```{r}
# Set between standard deviations 
# (these correspond to a fixed-effects model, the REML estimate for tau
# and the upper bound of the 95% CI for tau)
tau <- c(0, .53, 0.71)

x <- drop_na(dat_boot, yi)
```

In short, we simulate random values as new effect sizes under the assumption that the null hypothesis is true. The standard deviations of the simulated effect sizes are set to the observed standard deviations of the effect sizes in the original meta-analysis. This is done for each of the thousands of meta-analyses included in our study. The resulting 1,000 bootstrapped specification curves identify the lower and upper limits of the distribution of effect sizes under a scenario of heterogeneity equal to the random-effects model. These limits are represented by the 2.5% and 97.5% quantiles.

To simulate new data under the null hypothesis that the true treatment effect for depression is zero, we drew random values for the effect sizes from a normal distribution with mean zero. The standard deviation of this distribution was calculated using the formula:
sd = sqrt(tau^2 + variance of study ii)
where tau is a measure of between-study heterogeneity and vii is the variance of the effect size estimate for a given study.
For instance, in the case of the first study in your meta-analysis (which had an original effect size of Hedge's g = 1 and a variance of 0.2), the standard deviation of the normal distribution would be different in the three different bootstrapping scenarios:
•	If tau = 0 (fixed effect scenario with no heterogeneity), then sd = sqrt(0^2 + 0.2) = 0.2.
•	If tau = 0.51 (scenario with heterogeneity equal to the random-effects model), then sd = sqrt(0.51^2 + 0.2) = 0.54.
•	If tau = 0.72 (scenario with upper 95% CI estimate of tau from the random-effects model), then sd = sqrt(0.72^2 + 0.2) = 0.74.
The resulting new effect sizes would then be randomly drawn from these normal distributions and used in the descriptive specification curve analysis, which would be repeated 1,000 times in each scenario. This allowed us to identify the lower and upper limits of the resulting 1,000 bootstrapped specification curves, or the 2.5% and 97.5% quantiles. Exceeding these limits would indicate a deviation from the null hypothesis of no effect (g = 0).



```{r}
# Turn off warnings
options(warn = -1)

# Function boot_par carries out parametric bootstrap in for different
# values of tau
boot_par <- function(tau){
  d <- x
  d$yi  <- rnorm(nrow(d), 
                 mean = 0, 
                 sd = sqrt(tau^2+d$vi))
  out <- sort(
    unlist(
      lapply(sets, FUN = function(y) spec_list(y, data = d)) # mclapply
    )
  )
  out
}
```



```{r}
tictoc::tic("1000 iterations")
# Carry out boot_par() in parallel for each tau
for(j in 1:length(res)){
  cores <- 9
  cl <- makeCluster(cores) 
  registerDoParallel(cl)
  res[[j]] <- foreach(i=1:iter, 
                      .packages = c("tidyverse", "metafor", "parallel"), 
                      .combine = cbind) %dorng% {
                        boot_par(tau[j])
                      }
  stopCluster(cl)
}
tictoc::toc()
```


```{r}
# For each combination in spec, compute 2.5th and 97.5th 
# percentiles of the iter simulated effects 
temp_boot <- mclapply(1:3, function(x) { 
  lower <- apply(res[[x]], 1, function(y) {
    quantile(y, probs = .025)
  })
  upper <- apply(res[[x]], 1 , function(y){
    quantile(y, probs = .975)
  })
  
  out <- cbind(lower, upper)
  colnames(out) <- c(paste0("lower", x), paste0("upper",x))
  out
})
```

```{r}
# Collect the columns in temp_boot and add specification number 
# and estimated mean effects in res_male_full as columns
boot_tau <- data.frame(
  do.call(cbind, temp_boot),
  xvar = 1:no_spec,
  obs = sort(specifications_inferential_spec_curve$mean)
)
```


```{r}
#save(res, file = "data/tidy/res.RData")
#save(boot_tau, file = "data/tidy/boot_tau.RData")
load("data/tidy/boot_tau.RData")
```


```{r}
# List of percentag of estimated effects outside of respective 
# parametric bootstrap confidence ribbon
boot_outside <- 
c(
  tau_1 = mean(boot_tau$obs > boot_tau$upper1)+mean(boot_tau$obs < boot_tau$lower1),
  tau_2 = mean(boot_tau$obs > boot_tau$upper2)+mean(boot_tau$obs < boot_tau$lower2),
  tau_3 = mean(boot_tau$obs > boot_tau$upper3)+mean(boot_tau$obs < boot_tau$lower3)
)

# Next we're going to create labels for the facets in the parametric
# bootstrapping plots

facet_labs <- rep(NA, length(tau))
for (i in 1:length(tau)) {
  facet_labs[i] <- paste0(
    letters[i],
    ") ","tau", " = ",
    tau[i],
    ": ",
    format(boot_outside[i]*100, nsmall = 0, digits = 1),
    "% "
  )
}
```


```{r}
# Bring data into long format for plotting (so we can use different
# facets for each value of tau). [I know that pivot_longer() 
# and gather() were designed to do just that, but somehow I keep
# forgetting how to use these functions -- I thus concede]

boot_tau_long <- list()

for(i in 1:nrow(boot_tau)){
  boot_tau_long[[i]] <- data.frame(
    xvar = rep(boot_tau$xvar[i],3),
    obs = rep(boot_tau$obs[i],3),
    tau = factor(facet_labs),
    lb = c(boot_tau$lower1[i], boot_tau$lower2[i], boot_tau$lower3[i]),
    ub = c(boot_tau$upper1[i], boot_tau$upper2[i], boot_tau$upper3[i])
  )
}

# Collect entries in boot_tau_2 list
boot_tau_long <- do.call(rbind, boot_tau_long)
```

<br>

# Create Plots
```{r}
boot_plot <-
  ggplot(boot_tau_long, aes(
    x = xvar,
    y = obs,
    ymin = lb,
    ymax = ub
  )) +
  geom_ribbon(
    fill = "grey",
    alpha = 0.8,
    color = "black",
    lty = "dotted",
    size = 0.5
  ) +
  geom_line(color = "firebrick", size = 0.5) +
  geom_hline(yintercept = 0,
             lty = 2,
             size = 0.5) +
  scale_x_continuous(name = "Specification number") +
  scale_y_continuous(name = expression(paste('Hedges ', italic("g")))) +
  #ggtitle("Inferential Multiverse Meta-Analyses") +
  coord_cartesian(xlim = c(0.5, nrow(boot_tau) + 0.5),
                  expand = FALSE) +
  facet_grid( ~ tau) +
  theme(
    legend.position = c(0.15, 0.85),
    legend.title = element_text(size = 10, face = 'bold'),
    legend.key.height = unit('1', 'cm'),
    legend.key.width = unit('1', 'cm'),
    legend.text.align = 0,
    strip.text.x = element_text(size = 9, hjust = 0),
    strip.background = element_blank()
  ) +
  theme_bw()

boot_plot
```


```{r}
ggsave("boot_plot.pdf", 
       plot = boot_plot, 
       dpi = "retina",
       height = 20, 
       width = 25, 
       units = "cm")
```

