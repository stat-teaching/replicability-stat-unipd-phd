---
title: Multiverse
subtitle: Replicability Crisis in Science?
---

```{r}
#| label: setup
knitr::opts_chunk$set(echo = TRUE,
                      dev = "svg",
                      fig.align = "center")

library(kableExtra)
library(tidyverse)
library(cowplot)

specif <- readRDS("objects/plessen2023-specification-data.rds")
specif_res <- specif$specif |> 
  mutate(res = map(fit, filor::summary_rma)) |> 
  unnest(res)

mtheme <- function(){
  theme_minimal(15)
}

theme_set(mtheme())
```

# Multiverse analysis

## Multiverse analysis

steegen here

# Multiverse analysis principles

## Researcher degrees of freedom

A single dataset is not associated with a single, true analysis. There are many alternatives (scenarios) that the researcher consciously or not decide to report.

## Plausible vs all options

Not all scenarios are equally plausible or reasonable.

## The impact of different scenarios

The impact of choosing one alternative over another is not easy to predict and often neglegtec. The only option is formalizing a plausible multiverse and exploring the results.

# Multiverse meta-analysis

## Meta-analysis many choices

In meta-analysis there are a lot of arbitrary choices.

## An example from @Plessen2023-ex

![](img/plessen2023.png)

## An example from @Plessen2023-ex

- Over the last four decades, more than 80 meta-analyses have examined the efficacy of psychotherapies for depression
- More than 700 randomised controlled trials (RCTs)
- Not all these studies goes in the same direction

## An example from @Plessen2023-ex

Discrepancies in results could be due to:

### Which factors (which data to meta-analyze)

- inclusion/esclusion of a subset of studies (e.g., low quality studies)
- type of control group or control therapy
- ...

### How factors (how to meta-analyze)

- type of model (e.g., equal vs random)
- model complexity (two-level, three level, robust, etc.)
- correcting for publication bias

# Descriptive tools

## Estimated effect of interest

```{r}
specif_res |> 
  ggplot(aes(x = b)) +
  geom_histogram(bins = 50,
                 fill = "dodgerblue",
                 col = "black") +
  ylab("Frequency") +
  xlab("Estimated Effect") +
  geom_vline(xintercept = 0, col = "red") +
  geom_vline(xintercept = 0.25, col = "green")
```

## Estimated effect as a function of scenarios

```{r}
above <- specif_res |> 
  arrange(b) |> 
  mutate(id = 1:n()) |> 
  ggplot(aes(x = id, y = b)) +
  geom_segment(aes(xend = id, y = ci.lb, yend = ci.ub)) +
  geom_hline(yintercept = 0, col = "red") +
  geom_hline(yintercept = 0.25, col = "green") +
  theme(axis.title.y = element_blank(),
        axis.text.x = element_blank(),
        axis.title.x = element_blank())
  
below <- specif_res |> 
  arrange(b) |> 
  mutate(id = 1:n()) |> 
  pivot_longer(c(
    target_group,
    format,
    diagnosis,
    risk_of_bias,
    type,
    method
  )) |> 
  ggplot(aes(x = id, y = value)) +
  geom_raster() +
  theme(axis.title.y = element_blank(),
        axis.text.x = element_blank()) +
  xlab("Specification")

plot_grid(above, below, nrow = 2, align = "hv")
```

## Fixing a specific parameter

```{r}
specif_res |> 
  arrange(b) |> 
  mutate(id = 1:n()) |> 
  ggplot(aes(x = b, fill = diagnosis)) +
  geom_density()
```

# Inferential tools

## Specification Curve @Simonsohn2020-sr

The idea of the specification curve is both descriptive (see previous plots) and inferential.

Inferentially, the approach requires to generate a new dataset under the null hypothesis and compare with the observed value.

## Specification Curve in meta-analysis @Plessen2023-ex

@Plessen2023-ex describe how to implement the method for meta-analysis.

1. For each dataset/model generate $k_s$ data (where $k$ is the number of effect in the specification $s$) sampling from $\mathcal{N}(0,\sigma^2_{\epsilon_i} + \tau^2)$.
2. Fit the model (FE or RE)
3. Get the specification curve
4. Repeat 1-3 for a large number of times (e.g., 1000)
5. Compute the 2.5% and 95.75% quantiles
6. Check if the observed specification is outside the 95% CI

## Specification Curve in meta-analysis @Plessen2023-ex

```{r}
#| code-fold: true
specif$SD |> 
  filter(spec %in% sample(1:1000, 1)) |> 
  ggplot(aes(x = id, y = b)) +
  geom_line(aes(group = spec))
```

## Specification Curve in meta-analysis @Plessen2023-ex

```{r}
#| code-fold: true
specif$SD |> 
  filter(spec %in% sample(1:1000, 1)) |> 
  ggplot(aes(x = id, y = b)) +
  geom_line(aes(group = spec))
```

## Specification Curve in meta-analysis @Plessen2023-ex

```{r}
#| code-fold: true
specif$SD |> 
  filter(spec %in% sample(1:1000, 1)) |> 
  ggplot(aes(x = id, y = b)) +
  geom_line(aes(group = spec))
```

## Specification Curve in meta-analysis @Plessen2023-ex

```{r}
#| code-fold: true
specif_res <- specif_res |> 
  arrange(b) |> 
  mutate(id = 1:n())

ggplot(data = specif$SD,
       aes(x = id, y = b)) +
  geom_line(aes(group = spec)) +
  geom_line(data = specif_res,
            aes(x = id, y = b),
            col = "firebrick",
            lwd = 2)
```

## PIMA

**P**-selection **I**nference in **M**ultiverse **M**eta-analysis (PIMA) is an inferential approach to multiverse analysis is an inferential framework for:

- obtaining an overall p-value across the multiverse
- obtaining corrected p-values based on resampling methods

# Important aspects of multiverse analysis

## Important aspects of multiverse analysis

- Include only plausible scenarios. Regardless the aim (description or inference)

## References

- @Steegen2016-lz
- @Hall2022-mp for data visualization
- @Liu2021-xv for data visualization

